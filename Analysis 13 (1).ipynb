{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6953a6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 TF-IDF Terms, Their TF-IDF Scores, and Mean Sentiment Scores:\n",
      "+-------------+--------------------+----------------------+\n",
      "| TF-IDF Term |    TF-IDF Score    | Mean Sentiment Score |\n",
      "+-------------+--------------------+----------------------+\n",
      "|     help    | 70.46715072587402  | 0.08754857725708816  |\n",
      "|    patch    | 70.26160730078566  | 0.10968910391311423  |\n",
      "|     new     |  66.0696908496249  | 0.10852102132677166  |\n",
      "|   version   | 63.09831220287657  |  0.1092685866833221  |\n",
      "|     add     | 59.927751778157145 |  0.1124964082111929  |\n",
      "|    armor    |  55.9795217408617  | 0.11610211008925439  |\n",
      "|    crash    | 53.992563780176035 | 0.07865249317719923  |\n",
      "|    weapon   | 52.54324854156406  | 0.11505172502433282  |\n",
      "|    issue    | 51.53961491125254  | 0.08015527137970872  |\n",
      "|     pack    | 49.99589592024177  | 0.11797027220805398  |\n",
      "|    quest    | 48.26193384805999  | 0.11497342089290091  |\n",
      "|   overhaul  | 48.22443928706439  | 0.13206520304654745  |\n",
      "|     fix     | 46.309097261765494 | 0.08159271820996271  |\n",
      "|  animation  | 45.92993100412157  | 0.11733763058640316  |\n",
      "|   texture   | 44.66063262042995  | 0.11175236428961932  |\n",
      "|    change   |  42.0808615926658  |  0.0945751377343788  |\n",
      "|   problem   | 39.48143603225696  | 0.07417851888601895  |\n",
      "|     item    | 39.141093925693845 | 0.10436476579955807  |\n",
      "|     npc     | 38.810252496585164 |  0.1077190646123124  |\n",
      "|     xbox    | 38.48415412884492  | 0.12035909080012469  |\n",
      "+-------------+--------------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from textblob import TextBlob\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import numpy as np\n",
    "from prettytable import PrettyTable\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize the NLTK WordNet Lemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# List of custom words to be excluded from TF-IDF analysis\n",
    "custom_exclude_words = ['like', 'im', 'dont', 'use', 'skyrim', 'dont', 'ive', 'using', 'need', 'fo4',\n",
    "                       'mod', 'mods', 'game', 'x200b', 'know', 'want', 'looking', 'make', 'work', 'good',\n",
    "                       'really', 'way', 'play', 'time', 'tried', 'order', 'modpack', 'trying', 'got', 'playing', \n",
    "                       'doesnt', 'vanilla', 'start', 'working', 'wondering', 'look', 'thanks', 'installed',\n",
    "                       'think', 'file','load', 'thing', 'sure', 'try', 'menu', 'better']\n",
    "\n",
    "def extract_sentences_with_term(text, term):\n",
    "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text)\n",
    "    sentences_with_term = [sentence for sentence in sentences if term.lower() in sentence.lower()]\n",
    "    return sentences_with_term\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return ' '.join([wordnet_lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "with open('combined_data_CD.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract titles, self_text, comments, and replies from each post\n",
    "documents = []\n",
    "for post in data:\n",
    "    # Check if \"comments\" key exists and is a list\n",
    "    if \"comments\" in post and isinstance(post[\"comments\"], list):\n",
    "        comments_body = [comment[\"body\"] for comment in post[\"comments\"]]\n",
    "        \n",
    "        # Check if \"replies\" key exists in each comment and is a list\n",
    "        replies_body = [\n",
    "            reply[\"body\"]\n",
    "            for comment in post[\"comments\"]\n",
    "            if \"replies\" in comment and isinstance(comment[\"replies\"], list)\n",
    "            for reply in comment[\"replies\"]\n",
    "        ]\n",
    "        \n",
    "        # Combine title, self_text, comments, and replies\n",
    "        document = post[\"title\"] + \" \" + post[\"self_text\"] + \" \".join(comments_body + replies_body)\n",
    "        documents.append(lemmatize_text(document))\n",
    "    else:\n",
    "        # If \"comments\" key is missing or not a list, use only title and self_text\n",
    "        document = post[\"title\"] + \" \" + post[\"self_text\"]\n",
    "        documents.append(lemmatize_text(document))\n",
    "\n",
    "# Get the default English stop words\n",
    "english_stop_words = TfidfVectorizer(stop_words='english').get_stop_words()\n",
    "\n",
    "# Combine default English stop words with custom words\n",
    "exclude_words = list(set(english_stop_words).union(set(custom_exclude_words)))\n",
    "\n",
    "# Create a TfidfVectorizer with combined stop words\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=exclude_words)\n",
    "\n",
    "# Fit and transform the data\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "\n",
    "# Get feature names (words)\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Optional: Convert the TF-IDF matrix to a dense array for easier handling\n",
    "dense_tfidf_matrix = tfidf_matrix.toarray()\n",
    "\n",
    "# Dictionary to store TF-IDF scores for each term\n",
    "term_tfidf_dict = dict(zip(feature_names, np.sum(dense_tfidf_matrix, axis=0)))\n",
    "\n",
    "# Sort terms based on their TF-IDF scores in descending order\n",
    "sorted_terms = sorted(term_tfidf_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Extract top 20 terms\n",
    "top_n = 20\n",
    "top_terms = [term[0] for term in sorted_terms[:top_n]]\n",
    "\n",
    "# Dictionary to store mean sentiment scores for each term\n",
    "term_sentiments = {}\n",
    "\n",
    "# Create a table to print TF-IDF terms, TF-IDF scores, and mean sentiment scores\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"TF-IDF Term\", \"TF-IDF Score\", \"Mean Sentiment Score\"]\n",
    "\n",
    "# Lists to store data for scatter plot\n",
    "tfidf_scores = []\n",
    "sentiment_scores = []\n",
    "term_names = []\n",
    "\n",
    "# Iterate through each term and calculate mean sentiment\n",
    "for term in top_terms:\n",
    "    # Use the original term for printing, but use the lemmatized version for sentiment analysis\n",
    "    original_term = term\n",
    "    term = lemmatize_text(term)\n",
    "\n",
    "    sentences_with_term = []\n",
    "    for post in data:\n",
    "        combined_text = post[\"title\"] + \" \" + post[\"self_text\"]\n",
    "        \n",
    "        # Include comments and replies for sentiment analysis\n",
    "        if \"comments\" in post and isinstance(post[\"comments\"], list):\n",
    "            combined_text += \" \".join(comment[\"body\"] for comment in post[\"comments\"])\n",
    "            \n",
    "            for comment in post[\"comments\"]:\n",
    "                if \"replies\" in comment and isinstance(comment[\"replies\"], list):\n",
    "                    combined_text += \" \".join(reply[\"body\"] for reply in comment[\"replies\"])\n",
    "\n",
    "        sentences_with_term.extend(extract_sentences_with_term(combined_text, term))\n",
    "\n",
    "    sentiment_scores = [TextBlob(sentence).sentiment.polarity for sentence in sentences_with_term]\n",
    "    mean_sentiment = sum(sentiment_scores) / len(sentiment_scores) if sentiment_scores else None\n",
    "    tfidf_score = term_tfidf_dict[original_term]\n",
    "\n",
    "    term_sentiments[original_term] = mean_sentiment\n",
    "    table.add_row([original_term, tfidf_score, mean_sentiment])\n",
    "    \n",
    "    # Append data for scatter plot\n",
    "    tfidf_scores.append(tfidf_score)\n",
    "    sentiment_scores.append(mean_sentiment)\n",
    "    \n",
    "    \n",
    "# Print the table\n",
    "print(\"Top 20 TF-IDF Terms, Their TF-IDF Scores, and Mean Sentiment Scores:\")\n",
    "print(table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2365b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(tfidf_score, sentiment_scores, c='blue', label='Terms')\n",
    "plt.title('Scatter Plot of TF-IDF Scores vs Mean Sentiment Scores')\n",
    "plt.xlabel('TF-IDF Scores')\n",
    "plt.ylabel('Mean Sentiment Scores')\n",
    "\n",
    "# Annotate each point with the term name\n",
    "for i, term_name in enumerate(term_names):\n",
    "    plt.annotate(term_name, (tfidf_scores[i], sentiment_scores[i]), textcoords=\"offset points\", xytext=(0, 5), ha='center')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "365da80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 1: 254, fe, overhaulesp, sizet, rotaiting, dayz, rtti, zk383, cprogram, electroblobs\n",
      "\n",
      "Topic 2: help, patch, new, version, add, armor, crash, weapon, issue, pack\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Prepare the data for LDA\n",
    "lda_vectorizer = TfidfVectorizer(stop_words=exclude_words)\n",
    "lda_matrix = lda_vectorizer.fit_transform(documents)\n",
    "\n",
    "# Fit LDA model\n",
    "num_topics = 2  # You can adjust the number of topics\n",
    "lda_model = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "lda_model.fit(lda_matrix)\n",
    "\n",
    "# Display the top terms for each topic\n",
    "top_topic_terms = []\n",
    "for topic_idx, topic in enumerate(lda_model.components_):\n",
    "    top_terms_idx = topic.argsort()[:-10 - 1:-1]\n",
    "    top_terms_values = [feature_names[i] for i in top_terms_idx]\n",
    "    top_topic_terms.append(top_terms_values)\n",
    "\n",
    "# Print the top terms for each topic\n",
    "for i, terms in enumerate(top_topic_terms):\n",
    "    print(f\"\\nTopic {i + 1}: {', '.join(terms)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b9c1dfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Covariance between TF-IDF and LDA:\n",
      "Topic 1: 0.0\n",
      "Topic 2: 4.2760927777349025\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Extract terms common to both LDA and TF-IDF\n",
    "common_terms = set(top_terms) & set(term_tfidf_dict.keys())\n",
    "\n",
    "# Create arrays to store TF-IDF scores and LDA topic weights for common terms\n",
    "tfidf_scores = np.array([term_tfidf_dict[term] for term in common_terms])\n",
    "lda_weights = np.zeros((len(common_terms), num_topics))\n",
    "\n",
    "# Populate the LDA weights array\n",
    "for i, term in enumerate(common_terms):\n",
    "    for topic_idx, topic_terms in enumerate(top_topic_terms):\n",
    "        if term in topic_terms:\n",
    "            lda_weights[i, topic_idx] = 1  # Assign a weight of 1 if the term is present in the topic\n",
    "\n",
    "# Calculate covariance matrix\n",
    "covariance_matrix = np.cov(tfidf_scores, lda_weights, rowvar=False)\n",
    "\n",
    "# Extract the covariance between TF-IDF scores and each LDA topic\n",
    "covariance_tfidf_lda = covariance_matrix[0, 1:]\n",
    "\n",
    "# Print the covariance values\n",
    "print(\"\\nCovariance between TF-IDF and LDA:\")\n",
    "for topic_idx, cov_value in enumerate(covariance_tfidf_lda):\n",
    "    print(f\"Topic {topic_idx + 1}: {cov_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bb792fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic Coherence Score: 0.4735215430424002\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "# Convert the documents to a format suitable for Gensim\n",
    "tokenized_documents = [doc.split() for doc in documents]\n",
    "id2word = Dictionary(tokenized_documents)\n",
    "corpus = [id2word.doc2bow(text) for text in tokenized_documents]\n",
    "\n",
    "# Fit Gensim LDA model\n",
    "lda_model_gensim = LdaModel(corpus=corpus, id2word=id2word, num_topics=num_topics, random_state=42)\n",
    "\n",
    "# Calculate coherence score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model_gensim, texts=tokenized_documents, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print(f'\\nTopic Coherence Score: {coherence_lda}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
